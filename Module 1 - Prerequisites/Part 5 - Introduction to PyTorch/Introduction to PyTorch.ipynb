{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Introduction to PyTorch.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOtNsromGBwf/dQ9Dg/0nWh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=1mjMsKVMkSeZ68cAZenxBYByg5-Xb7vRM\" />"],"metadata":{"id":"OoZR8iS5nw-_"}},{"cell_type":"markdown","source":["### Contents\n","<ul>\n","    <li><a href='#1'>What is PyTorch?</a></li>\n","    <li><a href='#2'>What is tensor</a></li>\n","    <li><a href='#3'>What is CUDA</a></li>\n","    <li><a href='#4'>Creating a dataset</a></li>\n","    <li><a href='#5'>DataLoaders</a></li>\n","    <li><a href='#6'>Transforms</a></li>\n","    <li><a href='#7'>Creating a model</a></li>    \n","</ul>"],"metadata":{"id":"YYx9gt3W8cLt"}},{"cell_type":"markdown","source":["<div id='1'><h2>What is PyTorch?</h2></div>\n","<p>\n","PyTorch is an open source machine learning library based on the Torch library, used for applications such as computer vision and natural language processing, primarily developed by Facebook's AI Research lab. It is free and open-source software released under the Modified BSD license.\n","<br />\n","Click <a href=\"https://pytorch.org/\">here</a> for more information.\n","\n","\n","</p>"],"metadata":{"id":"vH4aU0gGqwIZ"}},{"cell_type":"code","source":["import numpy as np \n","import torch\n","import os\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn"],"metadata":{"id":"lsyV41exv1fc","executionInfo":{"status":"ok","timestamp":1639637794523,"user_tz":-210,"elapsed":6265,"user":{"displayName":"erfan asadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzQekZkDTia3o88wFJN01NFNQuyZCFPyluIWAeCg=s64","userId":"08055361749787217489"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["<div id='2'><h2>What is tensor?</h2></div>\n","A PyTorch Tensor is basically the same as a numpy array: it does not know anything about deep learning or computational graphs or gradients, and is just a generic n-dimensional array to be used for arbitrary numeric computation. ... To run operations on the GPU, just cast the Tensor to a cuda datatype.\n","<br />\n","Click <a href=\"https://pytorch.org/\">here</a> for more iinformation.\n"],"metadata":{"id":"sdLHGP3OtQ2u"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xwAkzBK_ns2R","executionInfo":{"status":"ok","timestamp":1639600251433,"user_tz":-210,"elapsed":382,"user":{"displayName":"erfan asadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzQekZkDTia3o88wFJN01NFNQuyZCFPyluIWAeCg=s64","userId":"08055361749787217489"}},"outputId":"eac13b91-8192-4f00-eb33-37d7c1fcd6a1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0., 0., 0.],\n","        [0., 0., 0.]])"]},"metadata":{},"execution_count":8}],"source":["torch.zeros((2, 3))"]},{"cell_type":"code","source":["torch.rand((5, 4))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X-FDCm7HyIti","executionInfo":{"status":"ok","timestamp":1639600251820,"user_tz":-210,"elapsed":7,"user":{"displayName":"erfan asadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzQekZkDTia3o88wFJN01NFNQuyZCFPyluIWAeCg=s64","userId":"08055361749787217489"}},"outputId":"c50af33f-9f7d-4d41-d30a-4e28cc1f981c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.0361, 0.5394, 0.7980, 0.8401],\n","        [0.0094, 0.5661, 0.0535, 0.7751],\n","        [0.1875, 0.1072, 0.9954, 0.3796],\n","        [0.7284, 0.2033, 0.0394, 0.0366],\n","        [0.5495, 0.5868, 0.7458, 0.2909]])"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["torch.from_numpy(np.zeros((2, 3)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DUrR-B0eyUfL","executionInfo":{"status":"ok","timestamp":1639600252500,"user_tz":-210,"elapsed":5,"user":{"displayName":"erfan asadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzQekZkDTia3o88wFJN01NFNQuyZCFPyluIWAeCg=s64","userId":"08055361749787217489"}},"outputId":"84111ab2-6319-4b95-913e-7529e730306c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0., 0., 0.],\n","        [0., 0., 0.]], dtype=torch.float64)"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["<div id='3'><h2>What is CUDA?</h2></div>\n","\n","CUDA is a parallel computing platform and programming model developed by Nvidia for general computing on its own GPUs (graphics processing units). CUDA enables developers to speed up compute-intensive applications by harnessing the power of GPUs for the parallelizable part of the computation.\n","\n","While there have been other proposed APIs for GPUs, such as OpenCL, and there are competitive GPUs from other companies, such as AMD, the combination of CUDA and Nvidia GPUs dominates several application areas, including deep learning, and is a foundation for some of the fastest computers in the world.\n","\n"],"metadata":{"id":"b6h1hxc6yzwl"}},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RPha61sqyh2O","executionInfo":{"status":"ok","timestamp":1639637794524,"user_tz":-210,"elapsed":6,"user":{"displayName":"erfan asadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzQekZkDTia3o88wFJN01NFNQuyZCFPyluIWAeCg=s64","userId":"08055361749787217489"}},"outputId":"5c419490-97c3-4f0d-d828-105953fe9968"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["zeros = torch.zeros((2, 3))\n","\n","# model.to(device)\n","\n","zeros_gpu = zeros.to(device)\n","\n","model(zeros_gpu)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cDlxynUdzXY8","executionInfo":{"status":"ok","timestamp":1639600519470,"user_tz":-210,"elapsed":8,"user":{"displayName":"erfan asadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzQekZkDTia3o88wFJN01NFNQuyZCFPyluIWAeCg=s64","userId":"08055361749787217489"}},"outputId":"37a4c95e-7af0-42af-a225-731820c34b85"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0., 0., 0.],\n","        [0., 0., 0.]])"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["<div id='4'><h2>Creating Dataset</h2></div>\n"],"metadata":{"id":"c3ephavW0UGP"}},{"cell_type":"code","source":["class FaceLandmarksDataset(Dataset):\n","    def __init__(self, csv_file, root_dir, transform=None):\n","        self.landmarks_frame = pd.read_csv(csv_file)\n","        self.root_dir = root_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.landmarks_frame)\n","\n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","\n","        img_name = os.path.join(self.root_dir,\n","                                self.landmarks_frame.iloc[idx, 0])\n","        image = io.imread(img_name)\n","        landmarks = self.landmarks_frame.iloc[idx, 1:]\n","        landmarks = np.array([landmarks])\n","        landmarks = landmarks.astype('float').reshape(-1, 2)\n","        sample = {'image': image, 'landmarks': landmarks}\n","\n","        if self.transform:\n","            sample = self.transform(sample)\n","\n","        return sample"],"metadata":{"id":"UTE50RY9znWk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<div id='5'><h2>Data Loaders</h2></div>\n","Combines a dataset and a sampler, and provides an iterable over the given dataset. The DataLoader supports both map-style and iterable-style datasets with single- or multi-process loading, customizing loading order and optional automatic batching (collation) and memory pinning."],"metadata":{"id":"JnqDtAvf4n9u"}},{"cell_type":"code","source":["dataloader = DataLoader(transformed_dataset, batch_size=4,\n","                        shuffle=True, num_workers=4)"],"metadata":{"id":"01vDGcdN34gi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<div id='5'><h2>Transforms</h2></div>\n","One issue we can see from the above is that the samples are not of the same size. Most neural networks expect the images of a fixed size. Therefore, we will need to write some preprocessing code. "],"metadata":{"id":"PKDAsCMl5E_Z"}},{"cell_type":"code","source":["# composed = transforms.Compose([Rescale(256),\n","#                                RandomCrop(224)])\n","\n","# tsfm = Transform(params)\n","# transformed_sample = tsfm(sample)"],"metadata":{"id":"iz9uRlZe5FHz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<div id='6'><h2>Models</h2></div>"],"metadata":{"id":"C4WzuOLL59z2"}},{"cell_type":"code","source":["class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super(NeuralNetwork, self).__init__()\n","        self.flatten = nn.Flatten()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(28*28, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 10),\n","        )\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        return logits\n","\n","model = NeuralNetwork().to(device)\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HBVGOjrs5auz","executionInfo":{"status":"ok","timestamp":1639602319266,"user_tz":-210,"elapsed":375,"user":{"displayName":"erfan asadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzQekZkDTia3o88wFJN01NFNQuyZCFPyluIWAeCg=s64","userId":"08055361749787217489"}},"outputId":"2809379b-532e-4baf-de4a-2db692b88115"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")\n"]}]},{"cell_type":"code","source":["class MLP(nn.Module):\n","    def __init__(self, n_inputs):\n","        super(MLP, self).__init__()\n","        self.layer = Linear(n_inputs, 1)\n","        self.activation = Sigmoid()\n"," \n","    def forward(self, X):\n","        X = self.layer(X)\n","        X = self.activation(X)\n","        return X"],"metadata":{"id":"7CiqjZR56Wrk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<hr />\n","\n","### About the author\n","\n","`Name`: Erfan Asadi\n","<br />\n","`Email`: erfanasadi.ce@gmail.com\n","<br />\n","`Linkedin`: https://www.linkedin.com/in/erfan-asadi-9b64b9163/\n","<br />\n","`GitHub`: https://github.com/ErfanAsadi\n","<br />\n","<hr />"],"metadata":{"id":"y_vo4w-B68ib"}}]}