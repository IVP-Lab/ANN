{"cells":[{"cell_type":"code","execution_count":23,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":408,"status":"ok","timestamp":1639633656193,"user":{"displayName":"erfan asadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzQekZkDTia3o88wFJN01NFNQuyZCFPyluIWAeCg=s64","userId":"08055361749787217489"},"user_tz":-210},"id":"nXkEgPb_vM4z"},"outputs":[],"source":["import torch\n","from torch.utils.data import DataLoader\n","import torchvision.datasets as datasets\n","from torchvision.transforms import ToTensor\n","import torch.nn as nn\n","\n","import matplotlib.pyplot as plt\n","\n","import time\n","import copy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"tVxA4SBO0mTe"},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1639633138405,"user":{"displayName":"erfan asadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzQekZkDTia3o88wFJN01NFNQuyZCFPyluIWAeCg=s64","userId":"08055361749787217489"},"user_tz":-210},"id":"hjgqYKDtvWyB"},"outputs":[],"source":["mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=ToTensor())\n","mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=ToTensor())"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1639633138405,"user":{"displayName":"erfan asadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzQekZkDTia3o88wFJN01NFNQuyZCFPyluIWAeCg=s64","userId":"08055361749787217489"},"user_tz":-210},"id":"zw0ZJjEUvXHC"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([60000, 28, 28])\n"]}],"source":["print(mnist_trainset.data.size())"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1639633138405,"user":{"displayName":"erfan asadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzQekZkDTia3o88wFJN01NFNQuyZCFPyluIWAeCg=s64","userId":"08055361749787217489"},"user_tz":-210},"id":"Ul6tmEcDvZ_T"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([10000, 28, 28])\n"]}],"source":["print(mnist_testset.data.size())"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":281},"executionInfo":{"elapsed":378,"status":"ok","timestamp":1639633186397,"user":{"displayName":"erfan asadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzQekZkDTia3o88wFJN01NFNQuyZCFPyluIWAeCg=s64","userId":"08055361749787217489"},"user_tz":-210},"id":"EJa2CI9NwC0S"},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANlUlEQVR4nO3dXaxVdXrH8d+vlEmMzAX4Qk8YXqZTTZw0BhSJqdhgyEwoXuBEYoaLKU0az1yg6SQTUmMv8LIxnZmMvSA5E81gQ53S4AsaY6HYyBh14sGggAgCRQF5cYLJgIlB9OnFWUyPuNfah7323msfnu8nOTl7r2evtZ9szo/1vv+OCAG48v1J0w0A6A/CDiRB2IEkCDuQBGEHkiDsQBKEHUiCsONrbJ+75OcL2//adF+o50+bbgCDJyKmXXxse5qkk5L+s7mO0A2s2dHOvZJOS/pt042gHsKOdlZLejK4rnrSM/+GKGN7rqTDkv4iIv636X5QD2t2VPmRpFcJ+pWBsKPK30ra0HQT6A4249GS7b+StE3Sn0XE2ab7QX2s2VFmtaSnCfqVgzU7kARrdiAJwg4kQdiBJAg7kERfb4SxzdFAoMciwq2m11qz215me7/tg7YfqrMsAL3V8ak321MkHZD0PUnHJL0paVVEvFsxD2t2oMd6sWZfJOlgRByOiPOSfiNpRY3lAeihOmGfJenouOfHimlfYXvY9qjt0RrvBaCmnh+gi4gRSSMSm/FAk+qs2Y9Lmj3u+beKaQAGUJ2wvynpBtvftv0NST+UtKU7bQHoto434yPigu0HJP2XpCmSnoiIvV3rDEBX9fWuN/bZgd7ryUU1ACYPwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASHY/PLkm2j0g6K+kLSRciYmE3mgLQfbXCXrgrIn7fheUA6CE244Ek6oY9JG21vdP2cKsX2B62PWp7tOZ7AajBEdH5zPasiDhu+3pJ2yQ9GBE7Kl7f+ZsBmJCIcKvptdbsEXG8+H1a0jOSFtVZHoDe6Tjstq+2/c2LjyV9X9KebjUGoLvqHI2fKekZ2xeX8+8R8VJXugLQdbX22S/7zdhnB3quJ/vsACYPwg4kQdiBJAg7kARhB5Loxo0wKaxcubK0dv/991fO+9FHH1XWP/vss8r6xo0bK+snT54srR08eLByXuTBmh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkuCutwk6fPhwaW3evHn9a6SFs2fPltb27t3bx04Gy7Fjx0prjz76aOW8o6OT91vUuOsNSI6wA0kQdiAJwg4kQdiBJAg7kARhB5LgfvYJqrpn/eabb66cd9++fZX1m266qbJ+yy23VNaXLFlSWrv99tsr5z169Ghlffbs2ZX1Oi5cuFBZ//jjjyvrQ0NDHb/3hx9+WFmfzOfZy7BmB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkuJ/9CjB9+vTS2vz58yvn3blzZ2X9tttu66iniWj3ffkHDhyorLe7fmHGjBmltTVr1lTOu379+sr6IOv4fnbbT9g+bXvPuGkzbG+z/X7xu/yvDcBAmMhm/K8lLbtk2kOStkfEDZK2F88BDLC2YY+IHZLOXDJ5haQNxeMNku7pcl8AuqzTa+NnRsSJ4vFJSTPLXmh7WNJwh+8DoEtq3wgTEVF14C0iRiSNSBygA5rU6am3U7aHJKn4fbp7LQHohU7DvkXS6uLxaknPdacdAL3S9jy77ackLZF0raRTktZJelbSJklzJH0g6b6IuPQgXqtlsRmPCbv33nsr65s2baqs79mzp7R21113Vc575kzbP+eBVXaeve0+e0SsKiktrdURgL7iclkgCcIOJEHYgSQIO5AEYQeS4BZXNOb666+vrO/evbvW/CtXriytbd68uXLeyYwhm4HkCDuQBGEHkiDsQBKEHUiCsANJEHYgCYZsRmPafZ3zddddV1n/5JNPKuv79++/7J6uZKzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJ7mdHT91xxx2ltZdffrly3qlTp1bWlyxZUlnfsWNHZf1Kxf3sQHKEHUiCsANJEHYgCcIOJEHYgSQIO5AE97Ojp5YvX15aa3ceffv27ZX1119/vaOesmq7Zrf9hO3TtveMm/aI7eO2dxU/5f+iAAbCRDbjfy1pWYvpv4iI+cXPi91tC0C3tQ17ROyQdKYPvQDooToH6B6w/U6xmT+97EW2h22P2h6t8V4Aauo07OslfUfSfEknJP2s7IURMRIRCyNiYYfvBaALOgp7RJyKiC8i4ktJv5K0qLttAei2jsJue2jc0x9I2lP2WgCDoe15dttPSVoi6VrbxyStk7TE9nxJIemIpB/3sEcMsKuuuqqyvmxZqxM5Y86fP18577p16yrrn3/+eWUdX9U27BGxqsXkx3vQC4Ae4nJZIAnCDiRB2IEkCDuQBGEHkuAWV9Sydu3ayvqCBQtKay+99FLlvK+99lpHPaE11uxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARDNqPS3XffXVl/9tlnK+uffvppaa3q9ldJeuONNyrraI0hm4HkCDuQBGEHkiDsQBKEHUiCsANJEHYgCe5nT+6aa66prD/22GOV9SlTplTWX3yxfMxPzqP3F2t2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUii7f3stmdLelLSTI0N0TwSEb+0PUPSf0iap7Fhm++LiE/aLIv72fus3Xnwdue6b7311sr6oUOHKutV96y3mxedqXM/+wVJP42I70q6XdIa29+V9JCk7RFxg6TtxXMAA6pt2CPiRES8VTw+K2mfpFmSVkjaULxsg6R7etUkgPoua5/d9jxJCyT9TtLMiDhRlE5qbDMfwICa8LXxtqdJ2izpJxHxB/v/dwsiIsr2x20PSxqu2yiAeia0Zrc9VWNB3xgRTxeTT9keKupDkk63mjciRiJiYUQs7EbDADrTNuweW4U/LmlfRPx8XGmLpNXF49WSnut+ewC6ZSKn3hZL+q2k3ZK+LCY/rLH99k2S5kj6QGOn3s60WRan3vrsxhtvrKy/9957tZa/YsWKyvrzzz9fa/m4fGWn3trus0fEq5JazixpaZ2mAPQPV9ABSRB2IAnCDiRB2IEkCDuQBGEHkuCrpK8Ac+fOLa1t3bq11rLXrl1bWX/hhRdqLR/9w5odSIKwA0kQdiAJwg4kQdiBJAg7kARhB5LgPPsVYHi4/Fu/5syZU2vZr7zySmW93fchYHCwZgeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJDjPPgksXry4sv7ggw/2qRNMZqzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJtufZbc+W9KSkmZJC0khE/NL2I5Lul/Rx8dKHI+LFXjWa2Z133llZnzZtWsfLPnToUGX93LlzHS8bg2UiF9VckPTTiHjL9jcl7bS9raj9IiL+pXftAeiWtmGPiBOSThSPz9reJ2lWrxsD0F2Xtc9ue56kBZJ+V0x6wPY7tp+wPb1knmHbo7ZHa3UKoJYJh932NEmbJf0kIv4gab2k70iar7E1/89azRcRIxGxMCIWdqFfAB2aUNhtT9VY0DdGxNOSFBGnIuKLiPhS0q8kLepdmwDqaht225b0uKR9EfHzcdOHxr3sB5L2dL89AN0ykaPxd0j6kaTdtncV0x6WtMr2fI2djjsi6cc96RC1vP3225X1pUuXVtbPnDnTzXbQoIkcjX9VkluUOKcOTCJcQQckQdiBJAg7kARhB5Ig7EAShB1Iwv0cctc24/sCPRYRrU6Vs2YHsiDsQBKEHUiCsANJEHYgCcIOJEHYgST6PWTz7yV9MO75tcW0QTSovQ1qXxK9daqbvc0tK/T1opqvvbk9OqjfTTeovQ1qXxK9dapfvbEZDyRB2IEkmg77SMPvX2VQexvUviR661Rfemt0nx1A/zS9ZgfQJ4QdSKKRsNteZnu/7YO2H2qihzK2j9jebXtX0+PTFWPonba9Z9y0Gba32X6/+N1yjL2GenvE9vHis9tle3lDvc22/T+237W91/Y/FNMb/ewq+urL59b3fXbbUyQdkPQ9ScckvSlpVUS829dGStg+ImlhRDR+AYbtv5Z0TtKTEfGXxbRHJZ2JiH8u/qOcHhH/OCC9PSLpXNPDeBejFQ2NH2Zc0j2S/k4NfnYVfd2nPnxuTazZF0k6GBGHI+K8pN9IWtFAHwMvInZIunRIlhWSNhSPN2jsj6XvSnobCBFxIiLeKh6flXRxmPFGP7uKvvqiibDPknR03PNjGqzx3kPSVts7bQ833UwLMyPiRPH4pKSZTTbTQtthvPvpkmHGB+az62T487o4QPd1iyPiFkl/I2lNsbk6kGJsH2yQzp1OaBjvfmkxzPgfNfnZdTr8eV1NhP24pNnjnn+rmDYQIuJ48fu0pGc0eENRn7o4gm7x+3TD/fzRIA3j3WqYcQ3AZ9fk8OdNhP1NSTfY/rbtb0j6oaQtDfTxNbavLg6cyPbVkr6vwRuKeouk1cXj1ZKea7CXrxiUYbzLhhlXw59d48OfR0TffyQt19gR+UOS/qmJHkr6+nNJbxc/e5vuTdJTGtus+1xjxzb+XtI1krZLel/Sf0uaMUC9/Zuk3ZLe0ViwhhrqbbHGNtHfkbSr+Fne9GdX0VdfPjculwWS4AAdkARhB5Ig7EAShB1IgrADSRB2IAnCDiTxf9b9XZp7EPQGAAAAAElFTkSuQmCC\n","text/plain":["\u003cFigure size 432x288 with 1 Axes\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["plt.imshow(mnist_testset.data[0], cmap='gray')\n","plt.title('%i' % mnist_testset.targets[0])\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"7_Uqy9AQw_9v"},"source":["Single- and Multi-process Data Loading\u003cbr /\u003e\n","A DataLoader uses single-process data loading by default.\n","\n","Within a Python process, the Global Interpreter Lock (GIL) prevents true fully parallelizing Python code across threads. To avoid blocking computation code with data loading, PyTorch provides an easy switch to perform multi-process data loading by simply setting the argument num_workers to a positive integer.\n","\n","Single-process data loading (default)"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1639633315269,"user":{"displayName":"erfan asadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzQekZkDTia3o88wFJN01NFNQuyZCFPyluIWAeCg=s64","userId":"08055361749787217489"},"user_tz":-210},"id":"5hEpuh8zwJMp"},"outputs":[{"data":{"text/plain":["{'test': \u003ctorch.utils.data.dataloader.DataLoader at 0x7f966586add0\u003e,\n"," 'train': \u003ctorch.utils.data.dataloader.DataLoader at 0x7f96691e60d0\u003e}"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["data_loaders = {\n","    'train' : torch.utils.data.DataLoader(mnist_trainset, \n","                                          batch_size=100, \n","                                          shuffle=True, \n","                                          num_workers=1),\n","    \n","    'test'  : torch.utils.data.DataLoader(mnist_testset, \n","                                          batch_size=100, \n","                                          shuffle=True, \n","                                          num_workers=1),\n","}\n","data_loaders"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1639633909785,"user":{"displayName":"erfan asadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzQekZkDTia3o88wFJN01NFNQuyZCFPyluIWAeCg=s64","userId":"08055361749787217489"},"user_tz":-210},"id":"H6HsVDwUweGy"},"outputs":[],"source":["class MLP(nn.Module):\n","  def __init__(self, input_size=784, output_size=10):\n","    super(MLP, self).__init__()\n","    self.dense1 = nn.Linear(input_size, 120)\n","    self.dense2 = nn.Linear(120, 84)\n","    self.dense3 = nn.Linear(84, output_size)\n","\n","  def forward(self, X):\n","    X = self.dense1(X)\n","    X = torch.relu(X)\n","    X = self.dense2(X)\n","    X = torch.relu(X)\n","    X = self.dense3(X)\n","    X = torch.relu(X)\n","    return X"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1639633932082,"user":{"displayName":"erfan asadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzQekZkDTia3o88wFJN01NFNQuyZCFPyluIWAeCg=s64","userId":"08055361749787217489"},"user_tz":-210},"id":"1gErkTUpy-JS"},"outputs":[{"name":"stdout","output_type":"stream","text":["MLP(\n","  (dense1): Linear(in_features=784, out_features=120, bias=True)\n","  (dense2): Linear(in_features=120, out_features=84, bias=True)\n","  (dense3): Linear(in_features=84, out_features=10, bias=True)\n",")\n"]}],"source":["model = MLP()\n","print(model)"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1639633967493,"user":{"displayName":"erfan asadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzQekZkDTia3o88wFJN01NFNQuyZCFPyluIWAeCg=s64","userId":"08055361749787217489"},"user_tz":-210},"id":"pcV5htxuzCGS"},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1639634081094,"user":{"displayName":"erfan asadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzQekZkDTia3o88wFJN01NFNQuyZCFPyluIWAeCg=s64","userId":"08055361749787217489"},"user_tz":-210},"id":"sLaMrYLszLxR"},"outputs":[],"source":["epochs = 10\n","train_losses = []\n","test_losses = [] \n","train_correct = [] \n","test_correct = [] "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"qFUZn7II1Q0B"},"outputs":[{"ename":"TypeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-40-e76052afc5f8\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"]}],"source":["for inputs, labels in data_loaders[\"train\"]:\n","  print(inputs.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NAcpZsHtzjeS"},"outputs":[],"source":["for epoch in range(epochs):\n","  since = time.time()\n","  print('-' * 10);\n","  print('Epoch {}/{}'.format(epoch, epochs - 1))\n","  print('-' * 10)\n","\n","  for phase in ['train', 'val']:\n","    if phase == 'train':\n","        model.train()  # Set model to training mode\n","    else:\n","        model.eval()   # Set model to evaluate mode\n","\n","    running_loss = 0.0\n","    running_corrects = 0\n","\n","    for inputs, labels in data_loaders[phase]:\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward\n","        # track history if only in train\n","        with torch.set_grad_enabled(phase == 'train'):\n","            \n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","\n","            # backward + optimize only if in training phase\n","            if phase == 'train':\n","                loss.backward()\n","                optimizer.step()\n","\n","        running_loss += loss.item() * inputs.size(0)\n","\n","    epoch_loss = running_loss / len(data_loaders[phase].dataset)\n","    if phase == 'train':\n","        train_losses.append(epoch_loss)\n","    else:\n","        data_loaders.append(epoch_loss)\n","\n","    print('{} Loss: {:.4f}'.format(\n","        phase, epoch_loss))\n","\n","    # deep copy the model\n","    if phase == 'val' and epoch_loss \u003c best_loss:\n","        best_loss = epoch_loss\n","        best_model_wts = copy.deepcopy(model.state_dict())\n","\n","time_elapsed = time.time() - since\n","print('Training complete in {:.0f}m {:.0f}s'.format(\n","    time_elapsed // 60, time_elapsed % 60))\n","print('Best val Loss: {:4f}'.format(best_loss))\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOFtRaFm7QIarAabyMcO+iK","collapsed_sections":[],"name":"MNIST.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}